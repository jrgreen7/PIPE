{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from fastai.data.core import DataLoaders\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderSegmentation(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        super(DataLoaderSegmentation, self).__init__()\n",
    "        self.img_files = glob.glob(os.path.join(folder_path,'features','*.npy'))\n",
    "        self.mask_files = []\n",
    "        for img_path in self.img_files:\n",
    "             self.mask_files.append(os.path.join(folder_path,'masks',os.path.basename(img_path)) )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask_path = self.mask_files[index]\n",
    "            \n",
    "            data = np.load(img_path)\n",
    "            label = np.load(mask_path)\n",
    "            \n",
    "            data = torch.from_numpy(data).float()\n",
    "            label = torch.from_numpy(label).float()\n",
    "            \n",
    "            return F.interpolate(data.unsqueeze(0), (128, 128)).squeeze(0), F.interpolate(label.unsqueeze(0), (128, 128)).squeeze(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = DataLoaderSegmentation(os.path.join('data', 'yeast_processed', 'train'))\n",
    "ds_test = DataLoaderSegmentation(os.path.join('data', 'yeast_processed', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1445, 161)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.__len__(), ds_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.3400e+02,  1.3400e+02, -3.4000e+01,  ...,  6.5000e+01,\n",
       "           -1.6000e+01,  8.0000e+00],\n",
       "          [ 1.3400e+02,  1.3400e+02, -3.4000e+01,  ...,  6.5000e+01,\n",
       "           -1.6000e+01,  8.0000e+00],\n",
       "          [-3.4000e+01, -3.4000e+01,  2.0400e+02,  ...,  5.0000e+00,\n",
       "            9.7000e+01,  9.0000e+01],\n",
       "          ...,\n",
       "          [ 6.5000e+01,  6.5000e+01,  5.0000e+00,  ...,  7.3000e+02,\n",
       "            6.0000e+00,  1.5000e+01],\n",
       "          [-1.6000e+01, -1.6000e+01,  9.7000e+01,  ...,  6.0000e+00,\n",
       "            1.3000e+02,  7.2000e+01],\n",
       "          [ 8.0000e+00,  8.0000e+00,  9.0000e+01,  ...,  1.5000e+01,\n",
       "            7.2000e+01,  2.3070e+03]],\n",
       " \n",
       "         [[ 1.3212e-04,  1.3212e-04,  2.6424e-04,  ...,  1.1230e-02,\n",
       "            1.1362e-02,  1.1494e-02],\n",
       "          [ 1.3212e-04,  1.3212e-04,  2.6424e-04,  ...,  1.1230e-02,\n",
       "            1.1362e-02,  1.1494e-02],\n",
       "          [ 2.6424e-04,  2.6424e-04,  5.2847e-04,  ...,  2.2460e-02,\n",
       "            2.2724e-02,  2.2989e-02],\n",
       "          ...,\n",
       "          [ 1.1230e-02,  1.1230e-02,  2.2460e-02,  ...,  9.5455e-01,\n",
       "            9.6578e-01,  9.7701e-01],\n",
       "          [ 1.1362e-02,  1.1362e-02,  2.2724e-02,  ...,  9.6578e-01,\n",
       "            9.7714e-01,  9.8851e-01],\n",
       "          [ 1.1494e-02,  1.1494e-02,  2.2989e-02,  ...,  9.7701e-01,\n",
       "            9.8851e-01,  1.0000e+00]]]),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128, 128]), torch.Size([1, 128, 128]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.__getitem__(0)[0].shape, ds_train.__getitem__(0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(ds_train.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(ds_train, ds_test, bs=4, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 128, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.data.core.DataLoaders at 0x1ffabe18070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_camvid(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, models.resnet34, loss_func=BCELossFlat(axis=1), n_in=2, n_out=1, wd=1e-2, y_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicUnet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): UnetBlock(\n",
       "      (shuf): PixelShuffle_ICNR(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): PixelShuffle(upscale_factor=2)\n",
       "      )\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvLayer(\n",
       "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv2): ConvLayer(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): PixelShuffle_ICNR(\n",
       "      (0): ConvLayer(\n",
       "        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (1): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (9): ResizeToOrig()\n",
       "    (10): MergeLayer()\n",
       "    (11): ResBlock(\n",
       "      (convpath): Sequential(\n",
       "        (0): ConvLayer(\n",
       "          (0): Conv2d(98, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (0): Conv2d(98, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (idpath): Sequential()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): ConvLayer(\n",
       "      (0): Conv2d(98, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (13): SigmoidRange(low=0, high=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.set_num_threads(1)\n",
    "learn.model\n",
    "learn.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2070'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.002290867641568184, lr_steep=9.12010818865383e-07)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.728489</td>\n",
       "      <td>0.661305</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604911</td>\n",
       "      <td>0.549449</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542765</td>\n",
       "      <td>0.535859</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468225</td>\n",
       "      <td>0.527256</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.438997</td>\n",
       "      <td>0.541864</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.367044</td>\n",
       "      <td>0.635926</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.349354</td>\n",
       "      <td>0.589175</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.331405</td>\n",
       "      <td>0.537738</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.282606</td>\n",
       "      <td>0.573239</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.264995</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.226792</td>\n",
       "      <td>0.779496</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.233602</td>\n",
       "      <td>0.571421</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.264747</td>\n",
       "      <td>0.544913</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.212022</td>\n",
       "      <td>0.645172</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.222658</td>\n",
       "      <td>0.637966</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.239552</td>\n",
       "      <td>0.596957</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>0.599537</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.213585</td>\n",
       "      <td>0.571836</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.222049</td>\n",
       "      <td>0.522393</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.227944</td>\n",
       "      <td>0.594706</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.217775</td>\n",
       "      <td>0.581001</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.212938</td>\n",
       "      <td>0.522055</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>0.671867</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.214013</td>\n",
       "      <td>0.622105</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.241212</td>\n",
       "      <td>0.584248</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.287355</td>\n",
       "      <td>0.478960</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.253536</td>\n",
       "      <td>0.661262</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.216565</td>\n",
       "      <td>0.704638</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.252515</td>\n",
       "      <td>0.749571</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.242287</td>\n",
       "      <td>0.621544</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.224585</td>\n",
       "      <td>0.577836</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.220407</td>\n",
       "      <td>0.644806</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.222050</td>\n",
       "      <td>0.893900</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.217044</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.205696</td>\n",
       "      <td>0.752054</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.246458</td>\n",
       "      <td>0.555359</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.197518</td>\n",
       "      <td>0.661551</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.217630</td>\n",
       "      <td>0.539147</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.222732</td>\n",
       "      <td>0.576972</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.217678</td>\n",
       "      <td>0.645011</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.201178</td>\n",
       "      <td>0.585032</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.248034</td>\n",
       "      <td>0.602890</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.191843</td>\n",
       "      <td>0.734469</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.201433</td>\n",
       "      <td>0.924047</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.242949</td>\n",
       "      <td>0.569252</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.233689</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.195411</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.217260</td>\n",
       "      <td>0.646056</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.228890</td>\n",
       "      <td>0.691817</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.228104</td>\n",
       "      <td>0.820098</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.233606</td>\n",
       "      <td>0.679954</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.265231</td>\n",
       "      <td>0.526674</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.237295</td>\n",
       "      <td>0.935197</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.231668</td>\n",
       "      <td>0.887206</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.581976</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.315828</td>\n",
       "      <td>0.557539</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.332027</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.409343</td>\n",
       "      <td>0.672753</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.599113</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.548323</td>\n",
       "      <td>0.546558</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.615293</td>\n",
       "      <td>0.593455</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.599639</td>\n",
       "      <td>0.586789</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.603116</td>\n",
       "      <td>0.598076</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.591819</td>\n",
       "      <td>0.584206</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.581388</td>\n",
       "      <td>0.582106</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.594259</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.601328</td>\n",
       "      <td>0.603165</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.591638</td>\n",
       "      <td>0.598239</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.608275</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.578312</td>\n",
       "      <td>0.573496</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.586590</td>\n",
       "      <td>0.578901</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.592934</td>\n",
       "      <td>0.581241</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.578117</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.578536</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.570859</td>\n",
       "      <td>0.564241</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.579094</td>\n",
       "      <td>0.568621</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.575521</td>\n",
       "      <td>0.573706</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.586008</td>\n",
       "      <td>0.579205</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.563707</td>\n",
       "      <td>0.565102</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.582047</td>\n",
       "      <td>0.590028</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.585592</td>\n",
       "      <td>0.606277</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.570853</td>\n",
       "      <td>0.567215</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.580817</td>\n",
       "      <td>0.559081</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.579431</td>\n",
       "      <td>0.569776</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.573874</td>\n",
       "      <td>0.566945</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.579717</td>\n",
       "      <td>0.588489</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.577070</td>\n",
       "      <td>0.634688</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.570060</td>\n",
       "      <td>0.563210</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.569359</td>\n",
       "      <td>0.579372</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.578540</td>\n",
       "      <td>0.561752</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.563181</td>\n",
       "      <td>0.565635</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.561336</td>\n",
       "      <td>0.573733</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.583072</td>\n",
       "      <td>0.555189</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.553282</td>\n",
       "      <td>0.548368</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.554276</td>\n",
       "      <td>0.547220</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.536810</td>\n",
       "      <td>0.545494</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>0.543008</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.525362</td>\n",
       "      <td>0.540575</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.549438</td>\n",
       "      <td>0.542019</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(100, slice(1e-2), pct_start=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.8\n"
     ]
    }
   ],
   "source": [
    "print(fastai.__version__ ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
